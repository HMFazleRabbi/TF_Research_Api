{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "V8-yl-s-WKMG"
   },
   "source": [
    "# Lead Detection Inference Template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kFSqkTCdWKMI"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!export CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hV4P5gyTWKMI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.15.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import six.moves.urllib as urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from distutils.version import StrictVersion\n",
    "from collections import defaultdict\n",
    "from io import StringIO\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "from object_detection.utils import ops as utils_ops\n",
    "\n",
    "if StrictVersion(tf.__version__) < StrictVersion('1.12.0'):\n",
    "  raise ImportError('Please upgrade your TensorFlow installation to v1.12.*.')\n",
    "\n",
    "tf.__version__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wy72mWwAWKMK"
   },
   "source": [
    "## Env setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "v7m_NY_aWKMK"
   },
   "outputs": [],
   "source": [
    "# This is needed to display the images.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r5FNuiRPWKMN"
   },
   "source": [
    "## Object detection imports\n",
    "Here are the imports from the object detection module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "bm0_uNRnWKMN"
   },
   "outputs": [],
   "source": [
    "from utils import label_map_util\n",
    "\n",
    "from utils import visualization_utils as vis_util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cfn_tRFOWKMO"
   },
   "source": [
    "# Model preparation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VyPz_t8WWKMQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pb:\tD:\\FZ_WS\\JyNB\\TF_Research_Api_LD_2_0\\research\\object_detection\\inference_graph/V-11-wichtig\\frozen_inference_graph.pb\n",
      "Labelmap:\tdata\\lead_detection_label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "root_dir = os.getcwd()\n",
    "FROZEN_GRAPH_DIR='inference_graph/V-11-wichtig'\n",
    "\n",
    "# Path to frozen detection graph. This is the actual model that is used for the object detection.\n",
    "PATH_TO_FROZEN_GRAPH = os.path.join(root_dir, FROZEN_GRAPH_DIR, \"frozen_inference_graph.pb\")\n",
    "\n",
    "# List of the strings that is used to add correct label for each box.\n",
    "# PATH_TO_LABELS = os.path.join(root_dir, 'training_ocr_ssd_fpn_efficientnet', 'object-detection.pbtxt')\n",
    "PATH_TO_LABELS = os.path.join('data', 'lead_detection_label_map.pbtxt')\n",
    "print(\"Pb:\\t{}\\nLabelmap:\\t{}\".format(PATH_TO_FROZEN_GRAPH, PATH_TO_LABELS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YBcB9QHLWKMU"
   },
   "source": [
    "## Load a (frozen) Tensorflow model into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KezjCRVvWKMV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph import successful\n"
     ]
    }
   ],
   "source": [
    "detection_graph = tf.Graph()\n",
    "with detection_graph.as_default():\n",
    "  od_graph_def = tf.GraphDef()\n",
    "  with tf.gfile.GFile(PATH_TO_FROZEN_GRAPH, 'rb') as fid:\n",
    "    serialized_graph = fid.read()\n",
    "    od_graph_def.ParseFromString(serialized_graph)\n",
    "    tf.import_graph_def(od_graph_def, name='')\n",
    "    print('Graph import successful')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_1MVVTcLWKMW"
   },
   "source": [
    "## Loading label map\n",
    "Label maps map indices to category names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "hDbpHkiWWKMX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: {'id': 1, 'name': 'BODY'}, 2: {'id': 2, 'name': 'PIN'}}\n"
     ]
    }
   ],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(PATH_TO_LABELS, use_display_name=True)\n",
    "print(category_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EFsoUHvbWKMZ"
   },
   "source": [
    "## Helper code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "aSlYc3JkWKMa"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(image, grayscale = False):\n",
    "  (im_width, im_height) = image.size\n",
    "  if grayscale:\n",
    "      return np.repeat(np.asarray(image)[:, :, np.newaxis], 3, axis = 2)\n",
    "  else:\n",
    "      return np.array(image.getdata()).reshape(\n",
    "          (im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDirirectory(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        print (\"Creating {}\".format(path))\n",
    "    return path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "H0_1AGhrWKMc"
   },
   "source": [
    "# Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "jG-zn5ykWKMd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating debug/images_out-V-11-wichtig\\test\n",
      "Count TEST_IMAGE_PATHS:\t24\n",
      "DONE!\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "# Paths\n",
    "PATH_TO_IMAGES_DIR = \"images\"\n",
    "PATH_TO_TEST_IMAGES_DIR = os.path.join(PATH_TO_IMAGES_DIR, \"test\")\n",
    "PATH_TO_OUT_IMG_DIR = createDirirectory(\"debug/images_out-V-11-wichtig\")\n",
    "PATH_TO_OUT_TEST_IMAGES_DIR = os.path.join(PATH_TO_OUT_IMG_DIR, \"test\")\n",
    "\n",
    "# Image Path\n",
    "TEST_IMAGE_PATHS = [f for f in glob.glob(PATH_TO_TEST_IMAGES_DIR + \"/*.jpg\", recursive=True)]\n",
    "\n",
    "if (len(TEST_IMAGE_PATHS) >0) :\n",
    "    createDirirectory(PATH_TO_OUT_IMG_DIR)\n",
    "    createDirirectory(PATH_TO_OUT_TEST_IMAGES_DIR)\n",
    "\n",
    "# Size, in inches, of the output images.\n",
    "IMAGE_SIZE = (20, 10)\n",
    "print(\"Count TEST_IMAGE_PATHS:\\t{}\".format(len(TEST_IMAGE_PATHS)))\n",
    "print(\"DONE!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_inference_for_images(images_path, graph):\n",
    "    with graph.as_default():\n",
    "        #config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True,visible_device_list='1'))\n",
    "        config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n",
    "        with tf.Session(config = config) as sess:\n",
    "            output_dict_array = []\n",
    "            \n",
    "            for image_path in tqdm(images_path):\n",
    "                \n",
    "                image = Image.open(image_path)\n",
    "          \n",
    "                # Get handles to input and output tensors\n",
    "                ops = tf.get_default_graph().get_operations()\n",
    "                all_tensor_names = {output.name for op in ops for output in op.outputs}\n",
    "                tensor_dict = {}\n",
    "                for key in [\n",
    "                    'num_detections', 'detection_boxes', 'detection_scores',\n",
    "                    'detection_classes', 'detection_masks'\n",
    "                ]:\n",
    "                    tensor_name = key + ':0'\n",
    "                    if tensor_name in all_tensor_names:\n",
    "                        tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n",
    "                            tensor_name)\n",
    "                if 'detection_masks' in tensor_dict:\n",
    "                    detection_boxes = tf.squeeze(tensor_dict['detection_boxes'], [0])\n",
    "                    detection_masks = tf.squeeze(tensor_dict['detection_masks'], [0])\n",
    "                    # Reframe is required to translate mask from box coordinates to image coordinates and fit the image size.\n",
    "                    real_num_detection = tf.cast(tensor_dict['num_detections'][0], tf.int32)\n",
    "                    detection_boxes = tf.slice(detection_boxes, [0, 0], [real_num_detection, -1])\n",
    "                    detection_masks = tf.slice(detection_masks, [0, 0, 0], [real_num_detection, -1, -1])\n",
    "                    detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n",
    "                        detection_masks, detection_boxes, image.shape[0], image.shape[1])\n",
    "                    detection_masks_reframed = tf.cast(\n",
    "                        tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n",
    "                    # Follow the convention by adding back the batch dimension\n",
    "                    tensor_dict['detection_masks'] = tf.expand_dims(\n",
    "                        detection_masks_reframed, 0)\n",
    "                image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n",
    "                \n",
    "                # Run inference\n",
    "                output_dict = sess.run(tensor_dict,\n",
    "                                       feed_dict={image_tensor: np.expand_dims(image, 0)})\n",
    "\n",
    "                # all outputs are float32 numpy arrays, so convert types as appropriate\n",
    "                output_dict['num_detections'] = int(output_dict['num_detections'][0])\n",
    "                output_dict['detection_classes'] = output_dict[\n",
    "                    'detection_classes'][0].astype(np.uint8)\n",
    "                output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n",
    "                output_dict['detection_scores'] = output_dict['detection_scores'][0]\n",
    "                if 'detection_masks' in output_dict:\n",
    "                    output_dict['detection_masks'] = output_dict['detection_masks'][0]\n",
    "\n",
    "                output_dict_array.append(output_dict)\n",
    "  \n",
    "            \n",
    "    return output_dict_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference sess...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:08<00:00,  2.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# Predition\n",
    "images = []\n",
    "print(\"Running inference sess...\")\n",
    "start = time.time()\n",
    "output_dict_array = run_inference_for_images(TEST_IMAGE_PATHS, detection_graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "3a5wMHN8WKMh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                           | 0/24 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Visualize and Record Prediction Result...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\V510\\Anaconda3\\envs\\TF_15_Py36\\lib\\site-packages\\ipykernel_launcher.py:46: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 24/24 [00:31<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n",
      "39.391326665878296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from object_detection.utils import ops as utils_ops\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "\n",
    "# # Predition\n",
    "# images = []\n",
    "# print(\"Running inference sess...\")\n",
    "# start = time.time()\n",
    "# output_dict_array = run_inference_for_images(TEST_IMAGE_PATHS, detection_graph)\n",
    "\n",
    "# Visualize and Record Prediction Result\n",
    "print(\"Running Visualize and Record Prediction Result...\")\n",
    "for index, output_dict in enumerate(tqdm(output_dict_array)):\n",
    "    # Load Image\n",
    "    image_path = TEST_IMAGE_PATHS[index]\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    #image_np = load_image_into_numpy_array(image, grayscale=True)\n",
    "    image_np = load_image_into_numpy_array(image)\n",
    "    \n",
    "    if not (os.path.isdir(PATH_TO_OUT_TEST_IMAGES_DIR)):\n",
    "        os.makedirs(PATH_TO_OUT_TEST_IMAGES_DIR)\n",
    "    out_image_path = os.path.join( PATH_TO_OUT_TEST_IMAGES_DIR , os.path.basename(image_path))\n",
    "    out_text_path = out_image_path.replace('.jpg','.txt')\n",
    "        \n",
    "    #     if (output_dict['num_detections']<100):\n",
    "    #         print(\".\")\n",
    "    #         continue\n",
    "        \n",
    "    # Output Images\n",
    "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np,\n",
    "          output_dict['detection_boxes'],\n",
    "          output_dict['detection_classes'],\n",
    "          output_dict['detection_scores'],\n",
    "          category_index,\n",
    "          instance_masks=output_dict.get('detection_masks'),\n",
    "          use_normalized_coordinates=True,\n",
    "          line_thickness=3,\n",
    "          skip_scores=False,\n",
    "          skip_labels=True,\n",
    "        max_boxes_to_draw=256,\n",
    "        min_score_thresh=.0)\n",
    "    \n",
    "    plt.figure(figsize=IMAGE_SIZE)\n",
    "    plt.imshow(image_np)\n",
    "    plt.savefig(out_image_path)\n",
    "\n",
    "    \n",
    "    # Output Text\n",
    "    boxes = output_dict['detection_boxes']\n",
    "    # get all boxes from an array\n",
    "    max_boxes_to_draw = boxes.shape[0]\n",
    "    # get scores to get a threshold\n",
    "    scores = output_dict['detection_scores']\n",
    "    # this is set as a default but feel free to adjust it to your needs\n",
    "    width, height = image.size\n",
    "\n",
    "    detected_img_list = []\n",
    "    detected_class_list = []\n",
    "    detected_score_list = []\n",
    "    detected_x_min = []\n",
    "    detected_y_min = []\n",
    "    detected_x_max = []\n",
    "    detected_y_max = []\n",
    "\n",
    "    min_score_thresh=.5\n",
    "    # iterate over all objects found\n",
    "    for i in range(min(max_boxes_to_draw, boxes.shape[0])):\n",
    "      if scores is None or scores[i] > min_score_thresh:\n",
    "          # boxes[i] is the box which will be drawn\n",
    "          class_name = category_index[output_dict['detection_classes'][i]]['name']\n",
    "          confidence_score = scores[i]\n",
    "          y_min = boxes[i][0] * height\n",
    "          x_min = boxes[i][1] * width\n",
    "          y_max = boxes[i][2] * height\n",
    "          x_max = boxes[i][3] * width\n",
    "\n",
    "          detected_img_list.append(os.path.basename(image_path))\n",
    "          detected_class_list.append(class_name)\n",
    "          detected_score_list.append(confidence_score)\n",
    "          detected_x_min.append(int(x_min))\n",
    "          detected_y_min.append(int(y_min))\n",
    "          detected_x_max.append(int(x_max))\n",
    "          detected_y_max.append(int(y_max))\n",
    "        \n",
    "    myPrediction = pd.DataFrame({\n",
    "        'xmin': detected_x_min,\n",
    "        'ymin': detected_y_min,\n",
    "        'xmax': detected_x_max,\n",
    "        'ymax': detected_y_max,\n",
    "        'class': detected_class_list,\n",
    "        'scores': detected_score_list\n",
    "    })\n",
    "    myPrediction.to_csv(out_text_path,encoding='utf-8', header=None, index=False, sep=\",\")\n",
    "    \n",
    "\n",
    "print('Done')\n",
    "end = time.time()\n",
    "total_time = end - start\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detection distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library Complete\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "print(\"Library Complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detection distribution\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4     767\n",
       "3     692\n",
       "1     448\n",
       "2     284\n",
       "7     246\n",
       "5     110\n",
       "15     86\n",
       "6      85\n",
       "8      25\n",
       "23      9\n",
       "58      8\n",
       "25      8\n",
       "9       7\n",
       "26      6\n",
       "67      6\n",
       "56      5\n",
       "24      5\n",
       "54      4\n",
       "53      4\n",
       "55      4\n",
       "68      4\n",
       "64      3\n",
       "57      3\n",
       "61      3\n",
       "50      2\n",
       "16      2\n",
       "22      2\n",
       "71      2\n",
       "27      2\n",
       "51      2\n",
       "59      2\n",
       "63      2\n",
       "65      2\n",
       "70      2\n",
       "60      1\n",
       "52      1\n",
       "62      1\n",
       "46      1\n",
       "66      1\n",
       "49      1\n",
       "Name: detection_per_img, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "detection_per_img=[]\n",
    "for e in output_dict_array:\n",
    "    detection_per_img.append(e['num_detections'])\n",
    "\n",
    "df_detection_per_img = pd.DataFrame.from_dict({'detection_per_img': detection_per_img})\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.title(\"Detection distribution\")\n",
    "sns.barplot( x=df_detection_per_img['detection_per_img'].value_counts().index, y=df_detection_per_img['detection_per_img'].value_counts())\n",
    "print(\"Detection distribution\")\n",
    "df_detection_per_img['detection_per_img'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "object_detection_tutorial.ipynb?workspaceId=ronnyvotel:python_inference::citc",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
