{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "1.15.0\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sys\n",
    "import math\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "from nms import nms\n",
    "import glob as glob\n",
    "# This is needed to display the images.\n",
    "%matplotlib inline\n",
    "\n",
    "# This is needed since the notebook is stored in the object_detection folder.\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "# Import utilites\n",
    "from utils import label_map_util    #, get_label_map_dict\n",
    "from utils import visualization_utils as vis_util\n",
    "\n",
    "#### Helper Function\n",
    "def createDirectory(path):\n",
    "    if not os.path.isdir(path):\n",
    "        os.makedirs(path)\n",
    "        print (\"Creating {}\".format(path))\n",
    "    return path\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TM_PinPredction():\n",
    "    \n",
    "    #########################################\n",
    "    # Member Data structures\n",
    "    #########################################    \n",
    "    class Filter():\n",
    "        '''\n",
    "        Failed if the prediction is more than -+25% offset from the template center\n",
    "        '''\n",
    "        def assert_template_ycenter_inrange(self, ymin, ymax, y1, h):\n",
    "            cy = y1 + h/2\n",
    "            if (cy<(ymin + h/4) or cy>(ymax - h/4)):\n",
    "                return False\n",
    "            return True\n",
    "                \n",
    "    #########################################\n",
    "    # Member Methods\n",
    "    #########################################       \n",
    "    def __init__(self, dir_path, out_dir):\n",
    "        #Path to img and txt dir\n",
    "        self.dir_path=dir_path \n",
    "        self.out_dir=out_dir\n",
    "        self.ai_score_threshold=0.9\n",
    "        self.template_threshold=0.6\n",
    "    \n",
    "\n",
    "    def generate_txt_file_list(self):\n",
    "        txt_files = glob.glob(os.path.join(self.dir_path, \"*.txt\"))\n",
    "        \n",
    "        #Validation\n",
    "        for e in txt_files:\n",
    "            if \"classes.txt\" in e:\n",
    "                txt_files.remove(e)\n",
    "                continue\n",
    "            if not (os.path.isfile(e.replace(\".txt\", \".jpg\"))):\n",
    "                txt_files.remove(e)\n",
    "                print(\"Not Found: \", e)\n",
    "                \n",
    "        #Return\n",
    "        return txt_files\n",
    "    \n",
    "    def generate_prediction_using_template_matching(self, img_fname, txt_fname):\n",
    "        \n",
    "        #Read\n",
    "        txt_df=pd.read_csv(txt_fname, \n",
    "                    names=['x1', 'y1', 'x2', 'y2', 'class', 'score'],  \n",
    "                    dtype={'x1': np.int, 'y1': np.int, 'x2': np.int, 'y2': np.int, 'class':str, 'score': np.float64} )\n",
    "        \n",
    "        img = cv2.imread(img_fname, 0)\n",
    "        name = os.path.basename(img_fname)\n",
    "        \n",
    "        #Output\n",
    "        txt_out_fpath=os.path.join(self.out_dir, name.replace(\".jpg\", \".txt\"))\n",
    "        \n",
    "        #Limit\n",
    "        ymax = txt_df.max(axis = 0).to_dict()['y2']\n",
    "        ymin = txt_df.min(axis = 0).to_dict()['y1'] \n",
    "        \n",
    "        # GT\n",
    "        gt_img = img.copy()\n",
    "        gt_dir = createDirectory(os.path.join(self.out_dir,\"GT\"))\n",
    "        for i, r_row in txt_df.iterrows():\n",
    "            r = r_row.to_dict()\n",
    "            cv2.rectangle(gt_img, (r['x1'], r['y1']), (r['x2'], r['y2']), (255,0,255), 1)\n",
    "        cv2.imwrite(os.path.join(gt_dir, name), gt_img)\n",
    "\n",
    "        # Prediction\n",
    "        boxes =[]\n",
    "        scores =[]\n",
    "        ai_df = txt_df.copy()\n",
    "        for i, row in txt_df.iterrows():\n",
    "            e = row.to_dict()\n",
    "            if e['score']<self.ai_score_threshold:\n",
    "                continue\n",
    "\n",
    "            template = img.copy()[ e['y1']:e['y2'], e['x1']:e['x2']]\n",
    "            h, w =template.shape\n",
    "            res = cv2.matchTemplate(img,template,cv2.TM_CCOEFF_NORMED)\n",
    "            threshold = self.template_threshold\n",
    "            loc = np.where( res >= threshold)\n",
    "            temp =img.copy()\n",
    "            cboxes=[]\n",
    "            cscores=[]\n",
    "            for pt in zip(*loc[::-1]):\n",
    "                if not (self.filters.assert_template_ycenter_inrange(ymin, ymax, pt[1],h)):\n",
    "                    continue\n",
    "                cboxes.append((pt[0],pt[1],w,h))\n",
    "                score = res[pt[1], pt[0]]\n",
    "                cscores.append(score)\n",
    "\n",
    "            #Local NMS\n",
    "            for ibox in nms.boxes(cboxes, cscores): \n",
    "                boxes.append(cboxes[ibox])\n",
    "                scores.append(cscores[ibox])\n",
    "        \n",
    "        #Global Nms\n",
    "        test = img.copy()\n",
    "        with open(txt_out_fpath, 'w') as f:\n",
    "            for idx in nms.boxes(boxes, scores):\n",
    "                x1, y1, w, h=boxes[idx]\n",
    "                score = scores[idx]\n",
    "                cv2.rectangle(test, (x1, y1), (x1 + w, y1 + h), (255,255,255), 1)\n",
    "                f.write(\"{},{},{},{},{},{}\\n\".format(x1, y1, x1+w, y1+h, 'PIN', score))\n",
    "        \n",
    "        # Save\n",
    "        cv2.imwrite(txt_out_fpath.replace(\".txt\",\".jpg\"), test)\n",
    "\n",
    "                \n",
    "        #Comparative Image\n",
    "        cmp_dir = createDirectory(os.path.join(self.out_dir,\"CMP\"))\n",
    "        cmp_img = np.zeros(shape=[gt_img.shape[0]*2, gt_img.shape[1]], dtype=np.uint8)\n",
    "        cmp_img[0*gt_img.shape[0]:(0+1)*gt_img.shape[0], :gt_img.shape[1]] = gt_img.copy()\n",
    "        cmp_img[1*test.shape[0]:(1+1)*test.shape[0], :test.shape[1]] = test.copy()\n",
    "        cv2.imwrite(os.path.join(cmp_dir, name), cmp_img)\n",
    "        \n",
    "        \n",
    "    def predict_multiple_image(self):\n",
    "        self.filters = self.Filter()\n",
    "        txt_files = self.generate_txt_file_list()\n",
    "        for txt_file in txt_files:\n",
    "            img_fname = txt_file.replace(\".txt\", \".jpg\")    \n",
    "            self.generate_prediction_using_template_matching(img_fname, txt_file)\n",
    "            \n",
    "            \n",
    "\n",
    "    def predict_single_image(self,img_fname, txt_file):\n",
    "        self.filters = self.Filter()\n",
    "        self.generate_prediction_using_template_matching(img_fname, txt_file)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_dir = \"D:/FZ_WS/JyNB/TF_Research_Api_LD_2_0/research/object_detection/scripts/Samples/ML_Sample-5/Input\"\n",
    "out_dir = createDirectory (\"D:/FZ_WS/JyNB/TF_Research_Api_LD_2_0/research/object_detection/scripts/Samples/ML_Sample-5/Output\")\n",
    "# tm_model = TM_PinPredction(in_dir, out_dir)\n",
    "# tm_model.predict_multiple_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________\n",
    "### Ai outlier detector\n",
    "\n",
    "The target is to take all the boxes predicted by Ai and compare between each of them then pass flag the ones that are not a good fit\n",
    "\n",
    "**Steps**\n",
    "1. Read ai prediction csv file to a variable.\n",
    "2. Crop out all of the predicted roi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AI_Outlier_Detector():\n",
    "\n",
    "    #########################################\n",
    "    # Member Data structures\n",
    "    #########################################\n",
    "    class SideWiseFilter():\n",
    "            '''\n",
    "            Description\n",
    "                - Created to hold all the condition checks \n",
    "                - Ideally the member function should return true or false\n",
    "            '''\n",
    "            ################\n",
    "            # Member Methods\n",
    "            ################\n",
    "            def is_sideoffset_tl_section_valid(self, img):\n",
    "                    h, w = img.shape\n",
    "                    roi_x1 = int(w * 0.75)\n",
    "                    roi_y2 = int(h *0.5)\n",
    "                    roi = img.copy()[ :roi_y2, roi_x1:]\n",
    "                    _minVal, _maxVal, minLoc, maxLoc = cv2.minMaxLoc(roi, None)\n",
    "                    return _maxVal > 0\n",
    "            def is_sideoffset_tr_section_valid(self, img):\n",
    "                    h, w = img.shape\n",
    "                    roi_x2 = int(w * 0.25)\n",
    "                    roi_y2 = int(h *0.5)\n",
    "                    roi = img.copy()[ :roi_y2, :roi_x2]\n",
    "                    _minVal, _maxVal, minLoc, maxLoc = cv2.minMaxLoc(roi, None)\n",
    "                    return _maxVal > 0\n",
    "            def is_sideoffset_l_section_valid(self, img):\n",
    "                    h, w = img.shape\n",
    "                    roi_x1 = int(w * 0.85)\n",
    "                    roi_y1 = int(h *0.5)\n",
    "                    roi = img.copy()[ :, roi_x1:]\n",
    "                    _minVal, _maxVal, minLoc, maxLoc = cv2.minMaxLoc(roi, None)\n",
    "                    return _maxVal > 0\n",
    "            def is_sideoffset_r_section_valid(self, img):\n",
    "                    h, w = img.shape\n",
    "                    roi_x1 = int(w * 0.85)\n",
    "                    roi_y1 = int(h *0.5)\n",
    "                    roi = img.copy()[ :, roi_x1:]\n",
    "                    _minVal, _maxVal, minLoc, maxLoc = cv2.minMaxLoc(roi, None)\n",
    "                    return _maxVal > 0\n",
    "    \n",
    "    \n",
    "    class ExtendWiseFilter():\n",
    "            '''\n",
    "            Description\n",
    "                - Created to hold all the condition checks \n",
    "                - Ideally the member function should return true or false\n",
    "            '''\n",
    "            ################\n",
    "            # Member Methods\n",
    "            ################\n",
    "            def get_empty_leftpad(self, img):\n",
    "                h, w = img.shape\n",
    "                np.sum(img, axis=0)\n",
    "\n",
    "                \n",
    "    #########################################\n",
    "    # Member Methods\n",
    "    #########################################         \n",
    "    def __init__(self, dir_path, out_dir):\n",
    "        #Path to img and txt dir\n",
    "        self.dir_path=dir_path \n",
    "        self.out_dir=out_dir\n",
    "\n",
    "    def generate_txt_file_list(self):\n",
    "        txt_files = glob.glob(os.path.join(self.dir_path, \"*.txt\"))\n",
    "\n",
    "        #Validation\n",
    "        for e in txt_files:\n",
    "            if \"classes.txt\" in e:\n",
    "                txt_files.remove(e)\n",
    "                continue\n",
    "            if not (os.path.isfile(e.replace(\".txt\", \".jpg\"))):\n",
    "                txt_files.remove(e)\n",
    "                print(\"Not Found: \", e)\n",
    "\n",
    "        #Return\n",
    "        return txt_files\n",
    "\n",
    "\n",
    "    def read_data (self, img_fname, txt_fname):\n",
    "        txt_df=pd.read_csv(txt_fname, \n",
    "                    names=['x1', 'y1', 'x2', 'y2', 'class', 'score'],  \n",
    "                    dtype={'x1': np.int, 'y1': np.int, 'x2': np.int, 'y2': np.int, 'class':str, 'score': np.float64} )\n",
    "\n",
    "        img = cv2.imread(img_fname, 0)\n",
    "        return  img, txt_df\n",
    "\n",
    "\n",
    "    def  gen_cropped_imgarray(self, in_image, txt_df, img_array):\n",
    "        img=in_image.copy()\n",
    "        for i, row in txt_df.iterrows():\n",
    "            r = row.to_dict()\n",
    "            cropped_img = img[r['y1']:r['y2'], r['x1']:r['x2']]\n",
    "            img_array.append(cropped_img)\n",
    "\n",
    "    def print_img_array(self, img_array, xblock=4, titles=[]):\n",
    "        fig = plt.figure()\n",
    "        xblock = len(img_array) if xblock> len(img_array) else xblock\n",
    "        yblock=math.ceil(len(img_array)/xblock)\n",
    "        for i, img in enumerate(img_array):\n",
    "            subplot = fig.add_subplot(yblock, xblock, i +1)\n",
    "            if (len(titles)>0): subplot.set_title(titles[i])\n",
    "            plt.imshow(img, cmap='gray')\n",
    "            \n",
    "        \n",
    "\n",
    "    '''\n",
    "    Run\n",
    "    '''\n",
    "    def run_sidewise_pad_outlier_detector(self):\n",
    "        plt.close('all') \n",
    "        txt_files = self.generate_txt_file_list()\n",
    "        img_array=[]\n",
    "        img_threshold_array=[]\n",
    "        print(txt_files)\n",
    "        for txt_file in txt_files:\n",
    "            img_fname = txt_file.replace(\".txt\", \".jpg\")   \n",
    "            name = os.path.basename(img_fname)\n",
    "            img, txt_df = self.read_data (img_fname, txt_file)\n",
    "            self.gen_cropped_imgarray(img, txt_df, img_array)\n",
    "            print(name)\n",
    "        self.print_img_array(img_array, xblock=10)\n",
    "        \n",
    "        outlier_filter = self.Filter()\n",
    "        status_titles=[]\n",
    "        for img in img_array:\n",
    "            \n",
    "            # Otsu's thresholding after Gaussian filtering\n",
    "            blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "            ret3,img = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "            img_threshold_array.append(img)\n",
    "            \n",
    "            #Filter\n",
    "            if not (outlier_filter.is_sideoffset_tl_section_valid(img) ):\n",
    "                status_titles.append('FAIL')\n",
    "            elif not ( outlier_filter.is_sideoffset_tr_section_valid(img)):\n",
    "                status_titles.append('FAIL')\n",
    "            elif not ( outlier_filter.is_sideoffset_r_section_valid(img)):\n",
    "                status_titles.append('FAIL')\n",
    "            else:\n",
    "                status_titles.append('PASS')\n",
    "        self.print_img_array(img_threshold_array, xblock=10, titles=status_titles)\n",
    "        \n",
    "    \n",
    "    def run_extended_border_outlierdetector(self):\n",
    "            plt.close('all') \n",
    "            txt_files = self.generate_txt_file_list()\n",
    "            \n",
    "            # Declaration\n",
    "            img_array=[]\n",
    "            img_array_extleft=[]\n",
    "            img_array_extright=[]\n",
    "            img_threshold_array=[]\n",
    "            img_array_threshold_extleft=[]\n",
    "            img_array_threshold_extright=[]\n",
    "            \n",
    "            \n",
    "            \n",
    "            for txt_file in txt_files:\n",
    "                img_fname = txt_file.replace(\".txt\", \".jpg\")   \n",
    "                name = os.path.basename(img_fname)\n",
    "                img, txt_df = self.read_data (img_fname, txt_file)\n",
    "                \n",
    "                #Cropped\n",
    "                dx=5\n",
    "                for i, row in txt_df.iterrows():\n",
    "                    r = row.to_dict()\n",
    "                    h, w = img.shape\n",
    "                    print(r['x2'] - r['x1'])\n",
    "                    if  (r['x2'] - r['x1']) >21:\n",
    "                        print(\"skip\")\n",
    "                        continue\n",
    "                    dx = int(0.1 *(r['x2'] - r['x1'])) + 1\n",
    "                    print(dx)\n",
    "                    cropped_img = img[r['y1']:r['y2'], r['x1']:r['x2']]\n",
    "                    img_array.append(img.copy()[r['y1']:r['y2'], r['x1']:r['x2']])\n",
    "                    img_array_extleft.append(img.copy()[r['y1']:r['y2'], r['x1']-dx:r['x2']])\n",
    "                    img_array_extright.append(img.copy()[r['y1']:r['y2'], r['x1']:r['x2']+dx])\n",
    "            \n",
    "            # Thresholding\n",
    "            def apply_thresholding(img_array, img_threshold_array):\n",
    "                for img in img_array:\n",
    "                    # Otsu's thresholding after Gaussian filtering\n",
    "                    blur = cv2.GaussianBlur(img,(5,5),0)\n",
    "                    ret3,img = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "                    img_threshold_array.append(img)\n",
    "            \n",
    "            apply_thresholding(img_array, img_threshold_array)   \n",
    "            apply_thresholding(img_array_extleft, img_array_threshold_extleft)\n",
    "            apply_thresholding(img_array_extright, img_array_threshold_extright)     \n",
    "\n",
    "            \n",
    "            for i, img in enumerate(img_array):\n",
    "                vsum = np.sum(img_array_threshold_extleft[i], axis=0)\n",
    "                statuslf = np.sum(vsum[0:3])<1\n",
    "                cv2.imwrite(os.path.join(self.out_dir, \"img_array_threshold_extleft\"+str(i)+\"-\"+str(statuslf)+\".jpg\"), img_array_threshold_extleft[i])\n",
    "                \n",
    "                vsum = np.sum(img_array_threshold_extright[i], axis=0)\n",
    "                statusrt =  np.sum(vsum[-3:])<1 \n",
    "                print(str(i),\"Result\",str(statusrt and statuslf), \"\\tL Pad:\\t\", statuslf,\"\\tR Pad:\\t\", statusrt)\n",
    "                cv2.imwrite(os.path.join(self.out_dir, \"img_array_threshold_extright\"+str(i)+\"-\"+str(statusrt)+\".jpg\"), img_array_threshold_extright[i])\n",
    "                \n",
    "                \n",
    "                cv2.imwrite(os.path.join(self.out_dir, \"img_array\"+str(i)+\"-\"+str(statusrt and statuslf)+\".jpg\"), img)\n",
    "                cv2.imwrite(os.path.join(self.out_dir, \"img_threshold_array\"+str(i)+\"-\"+str(statusrt and statuslf)+\".jpg\"), img_threshold_array[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "skip\n",
      "22\n",
      "skip\n",
      "23\n",
      "skip\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "20\n",
      "3\n",
      "0 Result True \tL Pad:\t True \tR Pad:\t True\n",
      "1 Result False \tL Pad:\t True \tR Pad:\t False\n",
      "2 Result True \tL Pad:\t True \tR Pad:\t True\n",
      "3 Result True \tL Pad:\t True \tR Pad:\t True\n",
      "4 Result True \tL Pad:\t True \tR Pad:\t True\n",
      "5 Result True \tL Pad:\t True \tR Pad:\t True\n",
      "6 Result True \tL Pad:\t True \tR Pad:\t True\n",
      "7 Result False \tL Pad:\t True \tR Pad:\t False\n",
      "8 Result True \tL Pad:\t True \tR Pad:\t True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rm: D:/FZ_WS/JyNB/TF_Research_Api_LD_2_0/research/object_detection/scripts/Samples/Ai_Outlier-1/Output/*: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "in_dir = \"D:/FZ_WS/JyNB/TF_Research_Api_LD_2_0/research/object_detection/scripts/Samples/Ai_Outlier-1/Input\"\n",
    "out_dir = createDirectory (\"D:/FZ_WS/JyNB/TF_Research_Api_LD_2_0/research/object_detection/scripts/Samples/Ai_Outlier-1/Output\")\n",
    "!rm \"D:/FZ_WS/JyNB/TF_Research_Api_LD_2_0/research/object_detection/scripts/Samples/Ai_Outlier-1/Output/*\"\n",
    "detection_model = AI_Outlier_Detector(in_dir, out_dir)\n",
    "detection_model.run_extended_border_outlierdetector()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "from skimage.measure import compare_ssim\n",
    "\n",
    "for i, img in enumerate(img_threshold_array):\n",
    "    base = img.copy()\n",
    "    scores = []\n",
    "    for j, selected_img in enumerate(img_threshold_array):\n",
    "        resized_img = cv2.resize(selected_img.copy(), (base.shape[1],base.shape[0]) )\n",
    "        (score, diff) = compare_ssim(base, resized_img, full=True)\n",
    "        diff = (diff * 255).astype(\"uint8\")\n",
    "        scores.append(score)\n",
    "    #print(i, scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
